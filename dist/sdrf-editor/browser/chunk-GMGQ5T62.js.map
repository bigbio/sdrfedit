{
  "version": 3,
  "sources": ["src/app/core/services/llm/providers/gemini-provider.ts"],
  "sourcesContent": ["/**\n * Google Gemini LLM Provider\n *\n * Implements the Google AI Generative Language API with streaming support.\n * https://ai.google.dev/api/generate-content\n */\n\nimport {\n  LlmProviderType,\n  LlmProviderConfig,\n  LlmMessage,\n  LlmResponse,\n  LlmStreamChunk,\n  LlmUsage,\n} from '../../../models/llm';\nimport { BaseLlmProvider } from './base-provider';\n\n/**\n * Gemini content part.\n */\ninterface GeminiPart {\n  text: string;\n}\n\n/**\n * Gemini content (message).\n */\ninterface GeminiContent {\n  role: 'user' | 'model';\n  parts: GeminiPart[];\n}\n\n/**\n * Gemini generation config.\n */\ninterface GeminiGenerationConfig {\n  temperature?: number;\n  maxOutputTokens?: number;\n  topP?: number;\n  topK?: number;\n}\n\n/**\n * Gemini API request body.\n */\ninterface GeminiRequest {\n  contents: GeminiContent[];\n  systemInstruction?: {\n    parts: GeminiPart[];\n  };\n  generationConfig?: GeminiGenerationConfig;\n}\n\n/**\n * Gemini API response.\n */\ninterface GeminiResponse {\n  candidates: Array<{\n    content: {\n      parts: GeminiPart[];\n      role: string;\n    };\n    finishReason: 'STOP' | 'MAX_TOKENS' | 'SAFETY' | 'RECITATION' | 'OTHER';\n    safetyRatings?: Array<{\n      category: string;\n      probability: string;\n    }>;\n  }>;\n  usageMetadata?: {\n    promptTokenCount: number;\n    candidatesTokenCount: number;\n    totalTokenCount: number;\n  };\n}\n\n/**\n * Gemini streaming response chunk.\n */\ninterface GeminiStreamChunk {\n  candidates?: Array<{\n    content?: {\n      parts?: GeminiPart[];\n      role?: string;\n    };\n    finishReason?: string;\n  }>;\n  usageMetadata?: {\n    promptTokenCount: number;\n    candidatesTokenCount: number;\n    totalTokenCount: number;\n  };\n}\n\n/**\n * Google Gemini LLM Provider implementation.\n */\nexport class GeminiProvider extends BaseLlmProvider {\n  readonly name: LlmProviderType = 'gemini';\n  readonly supportsStreaming = true;\n\n  constructor(config: Partial<LlmProviderConfig> = {}) {\n    super(config);\n  }\n\n  protected getProviderType(): LlmProviderType {\n    return 'gemini';\n  }\n\n  /**\n   * Sends a completion request to Gemini.\n   */\n  async complete(messages: LlmMessage[]): Promise<LlmResponse> {\n    this.validateConfiguration();\n\n    const url = this.buildUrl('generateContent');\n    const body = this.buildRequestBody(messages);\n\n    const response = await this.fetchWithTimeout(url, {\n      method: 'POST',\n      headers: this.getHeaders(),\n      body: JSON.stringify(body),\n    });\n\n    if (!response.ok) {\n      const errorBody = await response.text();\n      throw this.createErrorFromResponse(response.status, errorBody);\n    }\n\n    const data: GeminiResponse = await response.json();\n    return this.convertResponse(data);\n  }\n\n  /**\n   * Streams a completion from Gemini.\n   */\n  async *stream(messages: LlmMessage[]): AsyncGenerator<LlmStreamChunk, void, unknown> {\n    this.validateConfiguration();\n\n    const url = this.buildUrl('streamGenerateContent');\n    const body = this.buildRequestBody(messages);\n\n    // Gemini uses a different streaming format (not SSE)\n    this.abortController = new AbortController();\n\n    const timeoutId = setTimeout(() => {\n      this.abortController?.abort();\n    }, this.config.timeoutMs || 60000);\n\n    try {\n      const response = await fetch(url, {\n        method: 'POST',\n        headers: this.getHeaders(),\n        body: JSON.stringify(body),\n        signal: this.abortController.signal,\n      });\n\n      if (!response.ok) {\n        const errorBody = await response.text();\n        throw this.createErrorFromResponse(response.status, errorBody);\n      }\n\n      if (!response.body) {\n        throw new Error('Response body is empty');\n      }\n\n      const reader = response.body.getReader();\n      const decoder = new TextDecoder();\n      let buffer = '';\n\n      while (true) {\n        const { done, value } = await reader.read();\n\n        if (done) {\n          break;\n        }\n\n        buffer += decoder.decode(value, { stream: true });\n\n        // Gemini returns newline-delimited JSON\n        const lines = buffer.split('\\n');\n        buffer = lines.pop() || '';\n\n        for (const line of lines) {\n          const trimmed = line.trim();\n          if (!trimmed || trimmed === '[' || trimmed === ']' || trimmed === ',') {\n            continue;\n          }\n\n          // Remove leading/trailing brackets or commas\n          let jsonStr = trimmed;\n          if (jsonStr.startsWith('[')) jsonStr = jsonStr.slice(1);\n          if (jsonStr.endsWith(']')) jsonStr = jsonStr.slice(0, -1);\n          if (jsonStr.endsWith(',')) jsonStr = jsonStr.slice(0, -1);\n\n          if (!jsonStr.trim()) continue;\n\n          try {\n            const chunk: GeminiStreamChunk = JSON.parse(jsonStr);\n            const candidate = chunk.candidates?.[0];\n\n            if (candidate?.content?.parts) {\n              const text = candidate.content.parts\n                .filter((p) => p.text)\n                .map((p) => p.text)\n                .join('');\n\n              yield {\n                content: text,\n                done: !!candidate.finishReason,\n                finishReason: candidate.finishReason || undefined,\n              };\n            }\n          } catch (e) {\n            // Skip malformed chunks\n            console.warn('Failed to parse Gemini stream chunk:', jsonStr, e);\n          }\n        }\n      }\n\n      // Process any remaining buffer\n      if (buffer.trim()) {\n        try {\n          let jsonStr = buffer.trim();\n          if (jsonStr.endsWith(']')) jsonStr = jsonStr.slice(0, -1);\n          if (jsonStr.endsWith(',')) jsonStr = jsonStr.slice(0, -1);\n\n          if (jsonStr) {\n            const chunk: GeminiStreamChunk = JSON.parse(jsonStr);\n            const candidate = chunk.candidates?.[0];\n\n            if (candidate?.content?.parts) {\n              const text = candidate.content.parts\n                .filter((p) => p.text)\n                .map((p) => p.text)\n                .join('');\n\n              yield {\n                content: text,\n                done: true,\n                finishReason: candidate.finishReason || 'STOP',\n              };\n            }\n          }\n        } catch {\n          // Ignore final buffer parse errors\n        }\n      }\n    } finally {\n      clearTimeout(timeoutId);\n    }\n  }\n\n  // ============ Private Methods ============\n\n  /**\n   * Builds the API URL.\n   */\n  private buildUrl(action: string): string {\n    const model = this.config.model;\n    const apiKey = this.config.apiKey;\n    return `${this.config.baseUrl}/models/${model}:${action}?key=${apiKey}`;\n  }\n\n  /**\n   * Gets request headers.\n   */\n  private getHeaders(): Record<string, string> {\n    return {\n      'Content-Type': 'application/json',\n    };\n  }\n\n  /**\n   * Builds the request body.\n   */\n  private buildRequestBody(messages: LlmMessage[]): GeminiRequest {\n    const { system, contents } = this.convertMessages(messages);\n\n    const body: GeminiRequest = {\n      contents,\n      generationConfig: {\n        temperature: this.config.temperature,\n        maxOutputTokens: this.config.maxTokens,\n      },\n    };\n\n    if (system) {\n      body.systemInstruction = {\n        parts: [{ text: system }],\n      };\n    }\n\n    return body;\n  }\n\n  /**\n   * Converts our message format to Gemini format.\n   */\n  private convertMessages(messages: LlmMessage[]): {\n    system: string | undefined;\n    contents: GeminiContent[];\n  } {\n    let system: string | undefined;\n    const contents: GeminiContent[] = [];\n\n    for (const msg of messages) {\n      if (msg.role === 'system') {\n        system = system ? `${system}\\n\\n${msg.content}` : msg.content;\n      } else {\n        contents.push({\n          role: msg.role === 'assistant' ? 'model' : 'user',\n          parts: [{ text: msg.content }],\n        });\n      }\n    }\n\n    // Ensure conversation starts with user\n    if (contents.length > 0 && contents[0].role !== 'user') {\n      contents.unshift({\n        role: 'user',\n        parts: [{ text: 'Please proceed with your analysis.' }],\n      });\n    }\n\n    return { system, contents };\n  }\n\n  /**\n   * Converts Gemini response to our format.\n   */\n  private convertResponse(data: GeminiResponse): LlmResponse {\n    const candidate = data.candidates?.[0];\n\n    // Extract text content\n    const content = candidate?.content?.parts\n      ?.filter((p) => p.text)\n      .map((p) => p.text)\n      .join('') || '';\n\n    const usage: LlmUsage | undefined = data.usageMetadata\n      ? {\n          promptTokens: data.usageMetadata.promptTokenCount,\n          completionTokens: data.usageMetadata.candidatesTokenCount,\n          totalTokens: data.usageMetadata.totalTokenCount,\n        }\n      : undefined;\n\n    return {\n      content,\n      finishReason: this.mapFinishReason(candidate?.finishReason),\n      usage,\n      raw: data,\n    };\n  }\n\n  /**\n   * Maps Gemini finish reasons to our standard format.\n   */\n  private mapFinishReason(\n    reason: string | undefined\n  ): 'stop' | 'length' | 'content_filter' | 'error' | undefined {\n    switch (reason) {\n      case 'STOP':\n        return 'stop';\n      case 'MAX_TOKENS':\n        return 'length';\n      case 'SAFETY':\n      case 'RECITATION':\n        return 'content_filter';\n      default:\n        return undefined;\n    }\n  }\n}\n\n/**\n * Factory function to create a Gemini provider.\n */\nexport function createGeminiProvider(\n  config?: Partial<LlmProviderConfig>\n): GeminiProvider {\n  return new GeminiProvider(config);\n}\n"],
  "mappings": ";;;;;;;;;;AAgGM,IAAO,iBAAP,cAA8B,gBAAe;EACxC,OAAwB;EACxB,oBAAoB;EAE7B,YAAY,SAAqC,CAAA,GAAE;AACjD,UAAM,MAAM;EACd;EAEU,kBAAe;AACvB,WAAO;EACT;;;;EAKM,SAAS,UAAsB;;AACnC,WAAK,sBAAqB;AAE1B,YAAM,MAAM,KAAK,SAAS,iBAAiB;AAC3C,YAAM,OAAO,KAAK,iBAAiB,QAAQ;AAE3C,YAAM,WAAW,MAAM,KAAK,iBAAiB,KAAK;QAChD,QAAQ;QACR,SAAS,KAAK,WAAU;QACxB,MAAM,KAAK,UAAU,IAAI;OAC1B;AAED,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,YAAY,MAAM,SAAS,KAAI;AACrC,cAAM,KAAK,wBAAwB,SAAS,QAAQ,SAAS;MAC/D;AAEA,YAAM,OAAuB,MAAM,SAAS,KAAI;AAChD,aAAO,KAAK,gBAAgB,IAAI;IAClC;;;;;EAKO,OAAO,UAAsB;;AAClC,WAAK,sBAAqB;AAE1B,YAAM,MAAM,KAAK,SAAS,uBAAuB;AACjD,YAAM,OAAO,KAAK,iBAAiB,QAAQ;AAG3C,WAAK,kBAAkB,IAAI,gBAAe;AAE1C,YAAM,YAAY,WAAW,MAAK;AAChC,aAAK,iBAAiB,MAAK;MAC7B,GAAG,KAAK,OAAO,aAAa,GAAK;AAEjC,UAAI;AACF,cAAM,WAAW,kBAAM,MAAM,KAAK;UAChC,QAAQ;UACR,SAAS,KAAK,WAAU;UACxB,MAAM,KAAK,UAAU,IAAI;UACzB,QAAQ,KAAK,gBAAgB;SAC9B;AAED,YAAI,CAAC,SAAS,IAAI;AAChB,gBAAM,YAAY,kBAAM,SAAS,KAAI;AACrC,gBAAM,KAAK,wBAAwB,SAAS,QAAQ,SAAS;QAC/D;AAEA,YAAI,CAAC,SAAS,MAAM;AAClB,gBAAM,IAAI,MAAM,wBAAwB;QAC1C;AAEA,cAAM,SAAS,SAAS,KAAK,UAAS;AACtC,cAAM,UAAU,IAAI,YAAW;AAC/B,YAAI,SAAS;AAEb,eAAO,MAAM;AACX,gBAAM,EAAE,MAAM,MAAK,IAAK,kBAAM,OAAO,KAAI;AAEzC,cAAI,MAAM;AACR;UACF;AAEA,oBAAU,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAI,CAAE;AAGhD,gBAAM,QAAQ,OAAO,MAAM,IAAI;AAC/B,mBAAS,MAAM,IAAG,KAAM;AAExB,qBAAW,QAAQ,OAAO;AACxB,kBAAM,UAAU,KAAK,KAAI;AACzB,gBAAI,CAAC,WAAW,YAAY,OAAO,YAAY,OAAO,YAAY,KAAK;AACrE;YACF;AAGA,gBAAI,UAAU;AACd,gBAAI,QAAQ,WAAW,GAAG;AAAG,wBAAU,QAAQ,MAAM,CAAC;AACtD,gBAAI,QAAQ,SAAS,GAAG;AAAG,wBAAU,QAAQ,MAAM,GAAG,EAAE;AACxD,gBAAI,QAAQ,SAAS,GAAG;AAAG,wBAAU,QAAQ,MAAM,GAAG,EAAE;AAExD,gBAAI,CAAC,QAAQ,KAAI;AAAI;AAErB,gBAAI;AACF,oBAAM,QAA2B,KAAK,MAAM,OAAO;AACnD,oBAAM,YAAY,MAAM,aAAa,CAAC;AAEtC,kBAAI,WAAW,SAAS,OAAO;AAC7B,sBAAM,OAAO,UAAU,QAAQ,MAC5B,OAAO,CAAC,MAAM,EAAE,IAAI,EACpB,IAAI,CAAC,MAAM,EAAE,IAAI,EACjB,KAAK,EAAE;AAEV,sBAAM;kBACJ,SAAS;kBACT,MAAM,CAAC,CAAC,UAAU;kBAClB,cAAc,UAAU,gBAAgB;;cAE5C;YACF,SAAS,GAAG;AAEV,sBAAQ,KAAK,wCAAwC,SAAS,CAAC;YACjE;UACF;QACF;AAGA,YAAI,OAAO,KAAI,GAAI;AACjB,cAAI;AACF,gBAAI,UAAU,OAAO,KAAI;AACzB,gBAAI,QAAQ,SAAS,GAAG;AAAG,wBAAU,QAAQ,MAAM,GAAG,EAAE;AACxD,gBAAI,QAAQ,SAAS,GAAG;AAAG,wBAAU,QAAQ,MAAM,GAAG,EAAE;AAExD,gBAAI,SAAS;AACX,oBAAM,QAA2B,KAAK,MAAM,OAAO;AACnD,oBAAM,YAAY,MAAM,aAAa,CAAC;AAEtC,kBAAI,WAAW,SAAS,OAAO;AAC7B,sBAAM,OAAO,UAAU,QAAQ,MAC5B,OAAO,CAAC,MAAM,EAAE,IAAI,EACpB,IAAI,CAAC,MAAM,EAAE,IAAI,EACjB,KAAK,EAAE;AAEV,sBAAM;kBACJ,SAAS;kBACT,MAAM;kBACN,cAAc,UAAU,gBAAgB;;cAE5C;YACF;UACF,QAAQ;UAER;QACF;MACF;AACE,qBAAa,SAAS;MACxB;IACF;;;;;;EAOQ,SAAS,QAAc;AAC7B,UAAM,QAAQ,KAAK,OAAO;AAC1B,UAAM,SAAS,KAAK,OAAO;AAC3B,WAAO,GAAG,KAAK,OAAO,OAAO,WAAW,KAAK,IAAI,MAAM,QAAQ,MAAM;EACvE;;;;EAKQ,aAAU;AAChB,WAAO;MACL,gBAAgB;;EAEpB;;;;EAKQ,iBAAiB,UAAsB;AAC7C,UAAM,EAAE,QAAQ,SAAQ,IAAK,KAAK,gBAAgB,QAAQ;AAE1D,UAAM,OAAsB;MAC1B;MACA,kBAAkB;QAChB,aAAa,KAAK,OAAO;QACzB,iBAAiB,KAAK,OAAO;;;AAIjC,QAAI,QAAQ;AACV,WAAK,oBAAoB;QACvB,OAAO,CAAC,EAAE,MAAM,OAAM,CAAE;;IAE5B;AAEA,WAAO;EACT;;;;EAKQ,gBAAgB,UAAsB;AAI5C,QAAI;AACJ,UAAM,WAA4B,CAAA;AAElC,eAAW,OAAO,UAAU;AAC1B,UAAI,IAAI,SAAS,UAAU;AACzB,iBAAS,SAAS,GAAG,MAAM;;EAAO,IAAI,OAAO,KAAK,IAAI;MACxD,OAAO;AACL,iBAAS,KAAK;UACZ,MAAM,IAAI,SAAS,cAAc,UAAU;UAC3C,OAAO,CAAC,EAAE,MAAM,IAAI,QAAO,CAAE;SAC9B;MACH;IACF;AAGA,QAAI,SAAS,SAAS,KAAK,SAAS,CAAC,EAAE,SAAS,QAAQ;AACtD,eAAS,QAAQ;QACf,MAAM;QACN,OAAO,CAAC,EAAE,MAAM,qCAAoC,CAAE;OACvD;IACH;AAEA,WAAO,EAAE,QAAQ,SAAQ;EAC3B;;;;EAKQ,gBAAgB,MAAoB;AAC1C,UAAM,YAAY,KAAK,aAAa,CAAC;AAGrC,UAAM,UAAU,WAAW,SAAS,OAChC,OAAO,CAAC,MAAM,EAAE,IAAI,EACrB,IAAI,CAAC,MAAM,EAAE,IAAI,EACjB,KAAK,EAAE,KAAK;AAEf,UAAM,QAA8B,KAAK,gBACrC;MACE,cAAc,KAAK,cAAc;MACjC,kBAAkB,KAAK,cAAc;MACrC,aAAa,KAAK,cAAc;QAElC;AAEJ,WAAO;MACL;MACA,cAAc,KAAK,gBAAgB,WAAW,YAAY;MAC1D;MACA,KAAK;;EAET;;;;EAKQ,gBACN,QAA0B;AAE1B,YAAQ,QAAQ;MACd,KAAK;AACH,eAAO;MACT,KAAK;AACH,eAAO;MACT,KAAK;MACL,KAAK;AACH,eAAO;MACT;AACE,eAAO;IACX;EACF;;AAMI,SAAU,qBACd,QAAmC;AAEnC,SAAO,IAAI,eAAe,MAAM;AAClC;",
  "names": []
}
