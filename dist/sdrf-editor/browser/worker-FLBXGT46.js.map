{
  "version": 3,
  "sources": ["src/app/workers/ai.worker.ts"],
  "sourcesContent": ["/// <reference lib=\"webworker\" />\n\n/**\n * AI Web Worker\n *\n * Handles LLM API calls in a separate thread to prevent blocking the UI.\n * Supports streaming responses back to the main thread.\n */\n\n// ============ Types ============\n\nexport type LlmProviderType = 'openai' | 'anthropic' | 'gemini' | 'ollama';\nexport type LlmMessageRole = 'system' | 'user' | 'assistant';\n\nexport interface LlmMessage {\n  role: LlmMessageRole;\n  content: string;\n}\n\nexport interface LlmProviderConfig {\n  provider: LlmProviderType;\n  apiKey?: string;\n  model: string;\n  baseUrl?: string;\n  timeoutMs?: number;\n  maxTokens?: number;\n  temperature?: number;\n}\n\nexport interface AiWorkerRequest {\n  id: string;\n  type: 'stream' | 'complete' | 'abort';\n  provider: LlmProviderType;\n  config: LlmProviderConfig;\n  messages: LlmMessage[];\n}\n\nexport interface AiWorkerResponse {\n  id: string;\n  type: 'chunk' | 'complete' | 'error' | 'aborted';\n  content?: string;\n  error?: string;\n}\n\n// ============ Default Configs ============\n\nconst DEFAULT_CONFIGS: Record<LlmProviderType, Partial<LlmProviderConfig>> = {\n  openai: {\n    model: 'gpt-4o-mini',\n    baseUrl: 'https://api.openai.com/v1',\n    timeoutMs: 60000,\n    maxTokens: 4096,\n    temperature: 0.3,\n  },\n  anthropic: {\n    model: 'claude-sonnet-4-20250514',\n    baseUrl: 'https://api.anthropic.com/v1',\n    timeoutMs: 60000,\n    maxTokens: 4096,\n    temperature: 0.3,\n  },\n  gemini: {\n    model: 'gemini-2.0-flash',\n    baseUrl: 'https://generativelanguage.googleapis.com/v1beta',\n    timeoutMs: 60000,\n    maxTokens: 4096,\n    temperature: 0.3,\n  },\n  ollama: {\n    model: 'qwen3',\n    baseUrl: 'http://localhost:11434',\n    timeoutMs: 120000,\n    maxTokens: 4096,\n    temperature: 0.3,\n  },\n};\n\n// ============ Request Tracking ============\n\nconst abortControllers = new Map<string, AbortController>();\n\n// ============ Streaming Implementations ============\n\n/**\n * Stream from OpenAI API\n */\nasync function* streamOpenAI(\n  config: LlmProviderConfig,\n  messages: LlmMessage[],\n  signal: AbortSignal\n): AsyncGenerator<string> {\n  const url = `${config.baseUrl}/chat/completions`;\n\n  const response = await fetch(url, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      'Authorization': `Bearer ${config.apiKey}`,\n    },\n    body: JSON.stringify({\n      model: config.model,\n      messages: messages.map(m => ({ role: m.role, content: m.content })),\n      max_tokens: config.maxTokens,\n      temperature: config.temperature,\n      stream: true,\n    }),\n    signal,\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`OpenAI API error (${response.status}): ${error}`);\n  }\n\n  const reader = response.body!.getReader();\n  const decoder = new TextDecoder();\n  let buffer = '';\n\n  try {\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n\n      buffer += decoder.decode(value, { stream: true });\n      const lines = buffer.split('\\n');\n      buffer = lines.pop() || '';\n\n      for (const line of lines) {\n        const trimmed = line.trim();\n        if (!trimmed || trimmed.startsWith(':')) continue;\n\n        if (trimmed.startsWith('data: ')) {\n          const data = trimmed.slice(6);\n          if (data === '[DONE]') return;\n\n          try {\n            const chunk = JSON.parse(data);\n            const content = chunk.choices?.[0]?.delta?.content;\n            if (content) yield content;\n          } catch {\n            // Skip malformed chunks\n          }\n        }\n      }\n    }\n  } finally {\n    reader.releaseLock();\n  }\n}\n\n/**\n * Stream from Anthropic API\n */\nasync function* streamAnthropic(\n  config: LlmProviderConfig,\n  messages: LlmMessage[],\n  signal: AbortSignal\n): AsyncGenerator<string> {\n  const url = `${config.baseUrl}/messages`;\n\n  // Separate system message\n  let systemPrompt: string | undefined;\n  const convertedMessages: Array<{ role: 'user' | 'assistant'; content: string }> = [];\n\n  for (const msg of messages) {\n    if (msg.role === 'system') {\n      systemPrompt = systemPrompt ? `${systemPrompt}\\n\\n${msg.content}` : msg.content;\n    } else {\n      convertedMessages.push({\n        role: msg.role as 'user' | 'assistant',\n        content: msg.content,\n      });\n    }\n  }\n\n  // Ensure conversation starts with user message\n  if (convertedMessages.length > 0 && convertedMessages[0].role !== 'user') {\n    convertedMessages.unshift({\n      role: 'user',\n      content: 'Please proceed with your analysis.',\n    });\n  }\n\n  const body: Record<string, unknown> = {\n    model: config.model,\n    messages: convertedMessages,\n    max_tokens: config.maxTokens || 4096,\n    temperature: config.temperature,\n    stream: true,\n  };\n\n  if (systemPrompt) {\n    body.system = systemPrompt;\n  }\n\n  const response = await fetch(url, {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json',\n      'x-api-key': config.apiKey || '',\n      'anthropic-version': '2023-06-01',\n    },\n    body: JSON.stringify(body),\n    signal,\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`Anthropic API error (${response.status}): ${error}`);\n  }\n\n  const reader = response.body!.getReader();\n  const decoder = new TextDecoder();\n  let buffer = '';\n\n  try {\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n\n      buffer += decoder.decode(value, { stream: true });\n      const lines = buffer.split('\\n');\n      buffer = lines.pop() || '';\n\n      for (const line of lines) {\n        const trimmed = line.trim();\n        if (!trimmed || trimmed.startsWith(':')) continue;\n\n        if (trimmed.startsWith('data: ')) {\n          const data = trimmed.slice(6);\n          try {\n            const event = JSON.parse(data);\n            if (event.type === 'content_block_delta' && event.delta?.type === 'text_delta') {\n              yield event.delta.text;\n            }\n          } catch {\n            // Skip malformed events\n          }\n        }\n      }\n    }\n  } finally {\n    reader.releaseLock();\n  }\n}\n\n/**\n * Stream from Google Gemini API\n */\nasync function* streamGemini(\n  config: LlmProviderConfig,\n  messages: LlmMessage[],\n  signal: AbortSignal\n): AsyncGenerator<string> {\n  // Separate system message and convert to Gemini format\n  let systemInstruction: string | undefined;\n  const contents: Array<{ role: 'user' | 'model'; parts: Array<{ text: string }> }> = [];\n\n  for (const msg of messages) {\n    if (msg.role === 'system') {\n      systemInstruction = systemInstruction ? `${systemInstruction}\\n\\n${msg.content}` : msg.content;\n    } else {\n      contents.push({\n        role: msg.role === 'assistant' ? 'model' : 'user',\n        parts: [{ text: msg.content }],\n      });\n    }\n  }\n\n  // Ensure conversation starts with user\n  if (contents.length > 0 && contents[0].role !== 'user') {\n    contents.unshift({\n      role: 'user',\n      parts: [{ text: 'Please proceed with your analysis.' }],\n    });\n  }\n\n  const body: Record<string, unknown> = {\n    contents,\n    generationConfig: {\n      temperature: config.temperature,\n      maxOutputTokens: config.maxTokens,\n    },\n  };\n\n  if (systemInstruction) {\n    body.systemInstruction = { parts: [{ text: systemInstruction }] };\n  }\n\n  const url = `${config.baseUrl}/models/${config.model}:streamGenerateContent?key=${config.apiKey}`;\n\n  const response = await fetch(url, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify(body),\n    signal,\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`Gemini API error (${response.status}): ${error}`);\n  }\n\n  const reader = response.body!.getReader();\n  const decoder = new TextDecoder();\n  let buffer = '';\n\n  try {\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n\n      buffer += decoder.decode(value, { stream: true });\n      const lines = buffer.split('\\n');\n      buffer = lines.pop() || '';\n\n      for (const line of lines) {\n        let jsonStr = line.trim();\n        if (!jsonStr || jsonStr === '[' || jsonStr === ']' || jsonStr === ',') continue;\n\n        // Remove array brackets and commas\n        if (jsonStr.startsWith('[')) jsonStr = jsonStr.slice(1);\n        if (jsonStr.endsWith(']')) jsonStr = jsonStr.slice(0, -1);\n        if (jsonStr.endsWith(',')) jsonStr = jsonStr.slice(0, -1);\n        if (!jsonStr.trim()) continue;\n\n        try {\n          const chunk = JSON.parse(jsonStr);\n          const text = chunk.candidates?.[0]?.content?.parts\n            ?.filter((p: { text?: string }) => p.text)\n            .map((p: { text: string }) => p.text)\n            .join('');\n          if (text) yield text;\n        } catch {\n          // Skip malformed chunks\n        }\n      }\n    }\n  } finally {\n    reader.releaseLock();\n  }\n}\n\n/**\n * Stream from Ollama API\n */\nasync function* streamOllama(\n  config: LlmProviderConfig,\n  messages: LlmMessage[],\n  signal: AbortSignal\n): AsyncGenerator<string> {\n  const url = `${config.baseUrl}/api/chat`;\n\n  const response = await fetch(url, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n      model: config.model,\n      messages: messages.map(m => ({ role: m.role, content: m.content })),\n      stream: true,\n      options: {\n        temperature: config.temperature,\n        num_predict: config.maxTokens,\n      },\n    }),\n    signal,\n  });\n\n  if (!response.ok) {\n    const error = await response.text();\n    throw new Error(`Ollama API error (${response.status}): ${error}`);\n  }\n\n  const reader = response.body!.getReader();\n  const decoder = new TextDecoder();\n  let buffer = '';\n\n  try {\n    while (true) {\n      const { done, value } = await reader.read();\n      if (done) break;\n\n      buffer += decoder.decode(value, { stream: true });\n      const lines = buffer.split('\\n');\n      buffer = lines.pop() || '';\n\n      for (const line of lines) {\n        const trimmed = line.trim();\n        if (!trimmed) continue;\n\n        try {\n          const chunk = JSON.parse(trimmed);\n          if (chunk.message?.content) {\n            yield chunk.message.content;\n          }\n        } catch {\n          // Skip malformed chunks\n        }\n      }\n    }\n  } finally {\n    reader.releaseLock();\n  }\n}\n\n// ============ Main Stream Function ============\n\nasync function* streamFromProvider(\n  request: AiWorkerRequest,\n  signal: AbortSignal\n): AsyncGenerator<string> {\n  const config: LlmProviderConfig = {\n    ...DEFAULT_CONFIGS[request.provider],\n    ...request.config,\n  };\n\n  switch (request.provider) {\n    case 'openai':\n      yield* streamOpenAI(config, request.messages, signal);\n      break;\n    case 'anthropic':\n      yield* streamAnthropic(config, request.messages, signal);\n      break;\n    case 'gemini':\n      yield* streamGemini(config, request.messages, signal);\n      break;\n    case 'ollama':\n      yield* streamOllama(config, request.messages, signal);\n      break;\n    default:\n      throw new Error(`Unknown provider: ${request.provider}`);\n  }\n}\n\n// ============ Non-Streaming Implementations ============\n\nasync function completeFromProvider(\n  request: AiWorkerRequest,\n  signal: AbortSignal\n): Promise<string> {\n  // For simplicity, use streaming and accumulate\n  let content = '';\n  for await (const chunk of streamFromProvider(request, signal)) {\n    content += chunk;\n  }\n  return content;\n}\n\n// ============ Message Handler ============\n\naddEventListener('message', async (event: MessageEvent<AiWorkerRequest>) => {\n  const request = event.data;\n\n  // Handle abort request\n  if (request.type === 'abort') {\n    const controller = abortControllers.get(request.id);\n    if (controller) {\n      controller.abort();\n      abortControllers.delete(request.id);\n    }\n    return;\n  }\n\n  // Create abort controller for this request\n  const abortController = new AbortController();\n  abortControllers.set(request.id, abortController);\n\n  // Set up timeout\n  const timeoutMs = request.config.timeoutMs || DEFAULT_CONFIGS[request.provider].timeoutMs || 60000;\n  const timeoutId = setTimeout(() => {\n    abortController.abort();\n  }, timeoutMs);\n\n  try {\n    if (request.type === 'stream') {\n      let fullContent = '';\n\n      for await (const chunk of streamFromProvider(request, abortController.signal)) {\n        fullContent += chunk;\n        postMessage({\n          id: request.id,\n          type: 'chunk',\n          content: chunk,\n        } as AiWorkerResponse);\n      }\n\n      postMessage({\n        id: request.id,\n        type: 'complete',\n        content: fullContent,\n      } as AiWorkerResponse);\n    } else {\n      const content = await completeFromProvider(request, abortController.signal);\n      postMessage({\n        id: request.id,\n        type: 'complete',\n        content,\n      } as AiWorkerResponse);\n    }\n  } catch (error) {\n    const errorMessage = error instanceof Error ? error.message : String(error);\n\n    if (errorMessage.includes('abort') || (error instanceof Error && error.name === 'AbortError')) {\n      postMessage({\n        id: request.id,\n        type: 'aborted',\n        error: 'Request was aborted',\n      } as AiWorkerResponse);\n    } else {\n      postMessage({\n        id: request.id,\n        type: 'error',\n        error: errorMessage,\n      } as AiWorkerResponse);\n    }\n  } finally {\n    clearTimeout(timeoutId);\n    abortControllers.delete(request.id);\n  }\n});\n\n// Signal that worker is loaded\npostMessage({ id: 'init', type: 'complete', content: 'AI Worker loaded' } as AiWorkerResponse);\n"],
  "mappings": ";AA8CA,IAAM,kBAAuE;AAAA,EAC3E,QAAQ;AAAA,IACN,OAAO;AAAA,IACP,SAAS;AAAA,IACT,WAAW;AAAA,IACX,WAAW;AAAA,IACX,aAAa;AAAA,EACf;AAAA,EACA,WAAW;AAAA,IACT,OAAO;AAAA,IACP,SAAS;AAAA,IACT,WAAW;AAAA,IACX,WAAW;AAAA,IACX,aAAa;AAAA,EACf;AAAA,EACA,QAAQ;AAAA,IACN,OAAO;AAAA,IACP,SAAS;AAAA,IACT,WAAW;AAAA,IACX,WAAW;AAAA,IACX,aAAa;AAAA,EACf;AAAA,EACA,QAAQ;AAAA,IACN,OAAO;AAAA,IACP,SAAS;AAAA,IACT,WAAW;AAAA,IACX,WAAW;AAAA,IACX,aAAa;AAAA,EACf;AACF;AAIA,IAAM,mBAAmB,oBAAI,IAA6B;AAO1D,gBAAgB,aACd,QACA,UACA,QACwB;AACxB,QAAM,MAAM,GAAG,OAAO,OAAO;AAE7B,QAAM,WAAW,MAAM,MAAM,KAAK;AAAA,IAChC,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,gBAAgB;AAAA,MAChB,iBAAiB,UAAU,OAAO,MAAM;AAAA,IAC1C;AAAA,IACA,MAAM,KAAK,UAAU;AAAA,MACnB,OAAO,OAAO;AAAA,MACd,UAAU,SAAS,IAAI,QAAM,EAAE,MAAM,EAAE,MAAM,SAAS,EAAE,QAAQ,EAAE;AAAA,MAClE,YAAY,OAAO;AAAA,MACnB,aAAa,OAAO;AAAA,MACpB,QAAQ;AAAA,IACV,CAAC;AAAA,IACD;AAAA,EACF,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,QAAQ,MAAM,SAAS,KAAK;AAClC,UAAM,IAAI,MAAM,qBAAqB,SAAS,MAAM,MAAM,KAAK,EAAE;AAAA,EACnE;AAEA,QAAM,SAAS,SAAS,KAAM,UAAU;AACxC,QAAM,UAAU,IAAI,YAAY;AAChC,MAAI,SAAS;AAEb,MAAI;AACF,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,UAAI,KAAM;AAEV,gBAAU,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAChD,YAAM,QAAQ,OAAO,MAAM,IAAI;AAC/B,eAAS,MAAM,IAAI,KAAK;AAExB,iBAAW,QAAQ,OAAO;AACxB,cAAM,UAAU,KAAK,KAAK;AAC1B,YAAI,CAAC,WAAW,QAAQ,WAAW,GAAG,EAAG;AAEzC,YAAI,QAAQ,WAAW,QAAQ,GAAG;AAChC,gBAAM,OAAO,QAAQ,MAAM,CAAC;AAC5B,cAAI,SAAS,SAAU;AAEvB,cAAI;AACF,kBAAM,QAAQ,KAAK,MAAM,IAAI;AAC7B,kBAAM,UAAU,MAAM,UAAU,CAAC,GAAG,OAAO;AAC3C,gBAAI,QAAS,OAAM;AAAA,UACrB,QAAQ;AAAA,UAER;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF,UAAE;AACA,WAAO,YAAY;AAAA,EACrB;AACF;AAKA,gBAAgB,gBACd,QACA,UACA,QACwB;AACxB,QAAM,MAAM,GAAG,OAAO,OAAO;AAG7B,MAAI;AACJ,QAAM,oBAA4E,CAAC;AAEnF,aAAW,OAAO,UAAU;AAC1B,QAAI,IAAI,SAAS,UAAU;AACzB,qBAAe,eAAe,GAAG,YAAY;AAAA;AAAA,EAAO,IAAI,OAAO,KAAK,IAAI;AAAA,IAC1E,OAAO;AACL,wBAAkB,KAAK;AAAA,QACrB,MAAM,IAAI;AAAA,QACV,SAAS,IAAI;AAAA,MACf,CAAC;AAAA,IACH;AAAA,EACF;AAGA,MAAI,kBAAkB,SAAS,KAAK,kBAAkB,CAAC,EAAE,SAAS,QAAQ;AACxE,sBAAkB,QAAQ;AAAA,MACxB,MAAM;AAAA,MACN,SAAS;AAAA,IACX,CAAC;AAAA,EACH;AAEA,QAAM,OAAgC;AAAA,IACpC,OAAO,OAAO;AAAA,IACd,UAAU;AAAA,IACV,YAAY,OAAO,aAAa;AAAA,IAChC,aAAa,OAAO;AAAA,IACpB,QAAQ;AAAA,EACV;AAEA,MAAI,cAAc;AAChB,SAAK,SAAS;AAAA,EAChB;AAEA,QAAM,WAAW,MAAM,MAAM,KAAK;AAAA,IAChC,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,gBAAgB;AAAA,MAChB,aAAa,OAAO,UAAU;AAAA,MAC9B,qBAAqB;AAAA,IACvB;AAAA,IACA,MAAM,KAAK,UAAU,IAAI;AAAA,IACzB;AAAA,EACF,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,QAAQ,MAAM,SAAS,KAAK;AAClC,UAAM,IAAI,MAAM,wBAAwB,SAAS,MAAM,MAAM,KAAK,EAAE;AAAA,EACtE;AAEA,QAAM,SAAS,SAAS,KAAM,UAAU;AACxC,QAAM,UAAU,IAAI,YAAY;AAChC,MAAI,SAAS;AAEb,MAAI;AACF,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,UAAI,KAAM;AAEV,gBAAU,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAChD,YAAM,QAAQ,OAAO,MAAM,IAAI;AAC/B,eAAS,MAAM,IAAI,KAAK;AAExB,iBAAW,QAAQ,OAAO;AACxB,cAAM,UAAU,KAAK,KAAK;AAC1B,YAAI,CAAC,WAAW,QAAQ,WAAW,GAAG,EAAG;AAEzC,YAAI,QAAQ,WAAW,QAAQ,GAAG;AAChC,gBAAM,OAAO,QAAQ,MAAM,CAAC;AAC5B,cAAI;AACF,kBAAM,QAAQ,KAAK,MAAM,IAAI;AAC7B,gBAAI,MAAM,SAAS,yBAAyB,MAAM,OAAO,SAAS,cAAc;AAC9E,oBAAM,MAAM,MAAM;AAAA,YACpB;AAAA,UACF,QAAQ;AAAA,UAER;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF,UAAE;AACA,WAAO,YAAY;AAAA,EACrB;AACF;AAKA,gBAAgB,aACd,QACA,UACA,QACwB;AAExB,MAAI;AACJ,QAAM,WAA8E,CAAC;AAErF,aAAW,OAAO,UAAU;AAC1B,QAAI,IAAI,SAAS,UAAU;AACzB,0BAAoB,oBAAoB,GAAG,iBAAiB;AAAA;AAAA,EAAO,IAAI,OAAO,KAAK,IAAI;AAAA,IACzF,OAAO;AACL,eAAS,KAAK;AAAA,QACZ,MAAM,IAAI,SAAS,cAAc,UAAU;AAAA,QAC3C,OAAO,CAAC,EAAE,MAAM,IAAI,QAAQ,CAAC;AAAA,MAC/B,CAAC;AAAA,IACH;AAAA,EACF;AAGA,MAAI,SAAS,SAAS,KAAK,SAAS,CAAC,EAAE,SAAS,QAAQ;AACtD,aAAS,QAAQ;AAAA,MACf,MAAM;AAAA,MACN,OAAO,CAAC,EAAE,MAAM,qCAAqC,CAAC;AAAA,IACxD,CAAC;AAAA,EACH;AAEA,QAAM,OAAgC;AAAA,IACpC;AAAA,IACA,kBAAkB;AAAA,MAChB,aAAa,OAAO;AAAA,MACpB,iBAAiB,OAAO;AAAA,IAC1B;AAAA,EACF;AAEA,MAAI,mBAAmB;AACrB,SAAK,oBAAoB,EAAE,OAAO,CAAC,EAAE,MAAM,kBAAkB,CAAC,EAAE;AAAA,EAClE;AAEA,QAAM,MAAM,GAAG,OAAO,OAAO,WAAW,OAAO,KAAK,8BAA8B,OAAO,MAAM;AAE/F,QAAM,WAAW,MAAM,MAAM,KAAK;AAAA,IAChC,QAAQ;AAAA,IACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,IAC9C,MAAM,KAAK,UAAU,IAAI;AAAA,IACzB;AAAA,EACF,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,QAAQ,MAAM,SAAS,KAAK;AAClC,UAAM,IAAI,MAAM,qBAAqB,SAAS,MAAM,MAAM,KAAK,EAAE;AAAA,EACnE;AAEA,QAAM,SAAS,SAAS,KAAM,UAAU;AACxC,QAAM,UAAU,IAAI,YAAY;AAChC,MAAI,SAAS;AAEb,MAAI;AACF,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,UAAI,KAAM;AAEV,gBAAU,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAChD,YAAM,QAAQ,OAAO,MAAM,IAAI;AAC/B,eAAS,MAAM,IAAI,KAAK;AAExB,iBAAW,QAAQ,OAAO;AACxB,YAAI,UAAU,KAAK,KAAK;AACxB,YAAI,CAAC,WAAW,YAAY,OAAO,YAAY,OAAO,YAAY,IAAK;AAGvE,YAAI,QAAQ,WAAW,GAAG,EAAG,WAAU,QAAQ,MAAM,CAAC;AACtD,YAAI,QAAQ,SAAS,GAAG,EAAG,WAAU,QAAQ,MAAM,GAAG,EAAE;AACxD,YAAI,QAAQ,SAAS,GAAG,EAAG,WAAU,QAAQ,MAAM,GAAG,EAAE;AACxD,YAAI,CAAC,QAAQ,KAAK,EAAG;AAErB,YAAI;AACF,gBAAM,QAAQ,KAAK,MAAM,OAAO;AAChC,gBAAM,OAAO,MAAM,aAAa,CAAC,GAAG,SAAS,OACzC,OAAO,CAAC,MAAyB,EAAE,IAAI,EACxC,IAAI,CAAC,MAAwB,EAAE,IAAI,EACnC,KAAK,EAAE;AACV,cAAI,KAAM,OAAM;AAAA,QAClB,QAAQ;AAAA,QAER;AAAA,MACF;AAAA,IACF;AAAA,EACF,UAAE;AACA,WAAO,YAAY;AAAA,EACrB;AACF;AAKA,gBAAgB,aACd,QACA,UACA,QACwB;AACxB,QAAM,MAAM,GAAG,OAAO,OAAO;AAE7B,QAAM,WAAW,MAAM,MAAM,KAAK;AAAA,IAChC,QAAQ;AAAA,IACR,SAAS,EAAE,gBAAgB,mBAAmB;AAAA,IAC9C,MAAM,KAAK,UAAU;AAAA,MACnB,OAAO,OAAO;AAAA,MACd,UAAU,SAAS,IAAI,QAAM,EAAE,MAAM,EAAE,MAAM,SAAS,EAAE,QAAQ,EAAE;AAAA,MAClE,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,aAAa,OAAO;AAAA,QACpB,aAAa,OAAO;AAAA,MACtB;AAAA,IACF,CAAC;AAAA,IACD;AAAA,EACF,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,QAAQ,MAAM,SAAS,KAAK;AAClC,UAAM,IAAI,MAAM,qBAAqB,SAAS,MAAM,MAAM,KAAK,EAAE;AAAA,EACnE;AAEA,QAAM,SAAS,SAAS,KAAM,UAAU;AACxC,QAAM,UAAU,IAAI,YAAY;AAChC,MAAI,SAAS;AAEb,MAAI;AACF,WAAO,MAAM;AACX,YAAM,EAAE,MAAM,MAAM,IAAI,MAAM,OAAO,KAAK;AAC1C,UAAI,KAAM;AAEV,gBAAU,QAAQ,OAAO,OAAO,EAAE,QAAQ,KAAK,CAAC;AAChD,YAAM,QAAQ,OAAO,MAAM,IAAI;AAC/B,eAAS,MAAM,IAAI,KAAK;AAExB,iBAAW,QAAQ,OAAO;AACxB,cAAM,UAAU,KAAK,KAAK;AAC1B,YAAI,CAAC,QAAS;AAEd,YAAI;AACF,gBAAM,QAAQ,KAAK,MAAM,OAAO;AAChC,cAAI,MAAM,SAAS,SAAS;AAC1B,kBAAM,MAAM,QAAQ;AAAA,UACtB;AAAA,QACF,QAAQ;AAAA,QAER;AAAA,MACF;AAAA,IACF;AAAA,EACF,UAAE;AACA,WAAO,YAAY;AAAA,EACrB;AACF;AAIA,gBAAgB,mBACd,SACA,QACwB;AACxB,QAAM,SAA4B;AAAA,IAChC,GAAG,gBAAgB,QAAQ,QAAQ;AAAA,IACnC,GAAG,QAAQ;AAAA,EACb;AAEA,UAAQ,QAAQ,UAAU;AAAA,IACxB,KAAK;AACH,aAAO,aAAa,QAAQ,QAAQ,UAAU,MAAM;AACpD;AAAA,IACF,KAAK;AACH,aAAO,gBAAgB,QAAQ,QAAQ,UAAU,MAAM;AACvD;AAAA,IACF,KAAK;AACH,aAAO,aAAa,QAAQ,QAAQ,UAAU,MAAM;AACpD;AAAA,IACF,KAAK;AACH,aAAO,aAAa,QAAQ,QAAQ,UAAU,MAAM;AACpD;AAAA,IACF;AACE,YAAM,IAAI,MAAM,qBAAqB,QAAQ,QAAQ,EAAE;AAAA,EAC3D;AACF;AAIA,eAAe,qBACb,SACA,QACiB;AAEjB,MAAI,UAAU;AACd,mBAAiB,SAAS,mBAAmB,SAAS,MAAM,GAAG;AAC7D,eAAW;AAAA,EACb;AACA,SAAO;AACT;AAIA,iBAAiB,WAAW,OAAO,UAAyC;AAC1E,QAAM,UAAU,MAAM;AAGtB,MAAI,QAAQ,SAAS,SAAS;AAC5B,UAAM,aAAa,iBAAiB,IAAI,QAAQ,EAAE;AAClD,QAAI,YAAY;AACd,iBAAW,MAAM;AACjB,uBAAiB,OAAO,QAAQ,EAAE;AAAA,IACpC;AACA;AAAA,EACF;AAGA,QAAM,kBAAkB,IAAI,gBAAgB;AAC5C,mBAAiB,IAAI,QAAQ,IAAI,eAAe;AAGhD,QAAM,YAAY,QAAQ,OAAO,aAAa,gBAAgB,QAAQ,QAAQ,EAAE,aAAa;AAC7F,QAAM,YAAY,WAAW,MAAM;AACjC,oBAAgB,MAAM;AAAA,EACxB,GAAG,SAAS;AAEZ,MAAI;AACF,QAAI,QAAQ,SAAS,UAAU;AAC7B,UAAI,cAAc;AAElB,uBAAiB,SAAS,mBAAmB,SAAS,gBAAgB,MAAM,GAAG;AAC7E,uBAAe;AACf,oBAAY;AAAA,UACV,IAAI,QAAQ;AAAA,UACZ,MAAM;AAAA,UACN,SAAS;AAAA,QACX,CAAqB;AAAA,MACvB;AAEA,kBAAY;AAAA,QACV,IAAI,QAAQ;AAAA,QACZ,MAAM;AAAA,QACN,SAAS;AAAA,MACX,CAAqB;AAAA,IACvB,OAAO;AACL,YAAM,UAAU,MAAM,qBAAqB,SAAS,gBAAgB,MAAM;AAC1E,kBAAY;AAAA,QACV,IAAI,QAAQ;AAAA,QACZ,MAAM;AAAA,QACN;AAAA,MACF,CAAqB;AAAA,IACvB;AAAA,EACF,SAAS,OAAO;AACd,UAAM,eAAe,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAE1E,QAAI,aAAa,SAAS,OAAO,KAAM,iBAAiB,SAAS,MAAM,SAAS,cAAe;AAC7F,kBAAY;AAAA,QACV,IAAI,QAAQ;AAAA,QACZ,MAAM;AAAA,QACN,OAAO;AAAA,MACT,CAAqB;AAAA,IACvB,OAAO;AACL,kBAAY;AAAA,QACV,IAAI,QAAQ;AAAA,QACZ,MAAM;AAAA,QACN,OAAO;AAAA,MACT,CAAqB;AAAA,IACvB;AAAA,EACF,UAAE;AACA,iBAAa,SAAS;AACtB,qBAAiB,OAAO,QAAQ,EAAE;AAAA,EACpC;AACF,CAAC;AAGD,YAAY,EAAE,IAAI,QAAQ,MAAM,YAAY,SAAS,mBAAmB,CAAqB;",
  "names": []
}
